{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plexmctqq0xV"
      },
      "source": [
        "建物データと浸水面標高ラスターデータから建物の被災データを生成。（必要手続き：Driveの接続）\n",
        "\n",
        "3_CalcFloodDEMRaster.ipynbの実行後は再起動させる必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6miOua5u8sih",
        "outputId": "d16cac7a-c36a-49ac-8681-49dbb31f841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Googleドライブの準備\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThhMHeyt3lCC"
      },
      "outputs": [],
      "source": [
        "#@title 日本の調査IDと自治体コードから住所情報を得る\n",
        "#詳しくは https://www.e-stat.go.jp/gis/statmap-search?page=1&type=2&aggregateUnitForBoundary=A&toukeiCode=00200521&toukeiYear=2020&serveyId=A002005212020&coordsys=1&format=shape&datum=2000\n",
        "\n",
        "survey_id = \"A002005212020\" #@param {type: \"string\"}\n",
        "pref_code = \"40\" #@param\n",
        "city_code = \"202\"  #@param\n",
        "# \"202\" # 大牟田市\n",
        "# \"203\" # 久留米市\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiWIAVi6pnpm"
      },
      "outputs": [],
      "source": [
        "# @title 設定するパラメータ\n",
        "\n",
        "# ケース名：解析を通して使います。\n",
        "casename = \"omuta-r2-giaj\" #\"omuta-r2\" # -giaj\" #\"kurume-r2\" # \"kurume-r2-GIAJ\"\n",
        "\n",
        "maxdepth = 0# 7 #0 # Set 0 for GIAJ flood data\n",
        "\n",
        "depthfactor = 1.0 # depth would be multiplied with this factor\n",
        "\n",
        "local_government_code = f\"{pref_code}{city_code}\"\n",
        "\n",
        "# 確認用画像出力用フラグ\n",
        "flg_checkDisp = False\n",
        "\n",
        "flg_dummy_realEstateID = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmDsB5-EpfHS"
      },
      "outputs": [],
      "source": [
        "# @title 詳細設定用パラメータ（基本的には操作不要）\n",
        "\n",
        "enable_savefig = False # 図をGoogleドライブに保存する？\n",
        "\n",
        "zoomlevel = 15 # DEM zoom level to fetch\n",
        "\n",
        "# デバッグ用出力\n",
        "global globalflag_debug\n",
        "\n",
        "# 保存先\n",
        "path_home = \"/content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/\"\n",
        "#path_cgml = path_home + \"/CityGML/\"\n",
        "path_dem = path_home + \"/DEM/\"\n",
        "path_case = path_home + casename + \"/\"\n",
        "path_upload = path_case + \"ForUpload/\"\n",
        "json_buildings = path_case+\"buildings_parsed.json\"\n",
        "json_boundary = path_case +\"boundary.json\"\n",
        "file_bbox = path_case + \"boundbox.npy\"\n",
        "file_dem_fmt = path_case + \"dem_{}_{}-{}_{}-{}.npz\"\n",
        "\n",
        "file_flooddem = path_case + \"flood_dem_{:04d}.npz\"\n",
        "file_flooddepth = path_case + \"flood_depth_{:04d}.npz\"\n",
        "\n",
        "path_heattile_tmp = \"heat/\"\n",
        "\n",
        "file_building_csv = path_upload + \"buildings.csv\"\n",
        "file_floodHeattile_yukauemokuzou_zip = path_upload+\"heatmap_yukaue_mokuzou.zip\"\n",
        "file_floodHeattile_yukashitamokuzou_zip = path_upload+\"heatmap_yukashita_mokuzou.zip\"\n",
        "file_floodHeattile_allmokuzou_zip = path_upload+\"heatmap_all_mokuzou.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIDzsoB53lCD",
        "outputId": "1d4a06af-ee7a-4a30-90f8-0472ea109814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR\n",
            "mkdir: cannot create directory ‘shapes’: File exists\n",
            "/content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/shapes\n",
            "ファイルがダウンロードされました: A002005212020DDSWC40202.zip\n",
            "mkdir: cannot create directory ‘A002005212020DDSWC40202’: File exists\n",
            "Archive:  A002005212020DDSWC40202.zip\n",
            "  inflating: A002005212020DDSWC40202/r2ka40202.shp  \n",
            "  inflating: A002005212020DDSWC40202/r2ka40202.shx  \n",
            "  inflating: A002005212020DDSWC40202/r2ka40202.dbf  \n",
            "  inflating: A002005212020DDSWC40202/r2ka40202.prj  \n",
            "/content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR\n"
          ]
        }
      ],
      "source": [
        "# @title shapeファイルをダウンロードする．\n",
        "%cd {path_home}\n",
        "!mkdir shapes\n",
        "%cd shapes\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from urllib.parse import unquote\n",
        "\n",
        "# ダウンロードするファイルのURL\n",
        "local_government_code = f\"{pref_code}{city_code}\"\n",
        "url = f\"https://www.e-stat.go.jp/gis/statmap-search/data?dlserveyId={survey_id}&code={local_government_code}&coordSys=1&format=shape&downloadType=5&datum=2000\"\n",
        "\n",
        "def get_filename_from_cd(cd):\n",
        "    \"\"\"\n",
        "    Content-Dispositionヘッダーからファイル名を取得する関数\n",
        "    \"\"\"\n",
        "    if not cd:\n",
        "        return None\n",
        "    fname = re.findall(\"filename\\*=UTF-8''(.+)\", cd)\n",
        "    if len(fname) == 0:\n",
        "        return None\n",
        "    return unquote(fname[0])\n",
        "\n",
        "# ファイルをダウンロードし保存する関数\n",
        "def download_file(url):\n",
        "    \"\"\"\n",
        "    指定されたURLからファイルをダウンロードし、Content-Dispositionヘッダーから取得したファイル名で保存する\n",
        "    \"\"\"\n",
        "    with requests.get(url, stream=True) as response:\n",
        "        response.raise_for_status()\n",
        "        filename = get_filename_from_cd(response.headers.get('content-disposition'))\n",
        "        if not filename:\n",
        "            filename = 'downloaded_file.zip'\n",
        "        with open(filename, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                file.write(chunk)\n",
        "        print(f\"ファイルがダウンロードされました: {filename}\")\n",
        "    return filename\n",
        "\n",
        "# ファイルのダウンロード\n",
        "shp_filename = download_file(url)\n",
        "\n",
        "import os\n",
        "shape_dir = os.path.splitext(shp_filename)[0]\n",
        "!mkdir {shape_dir}\n",
        "!unzip -o {shp_filename} -d {shape_dir}\n",
        "\n",
        "%cd {path_home}\n",
        "from glob import glob\n",
        "\n",
        "address_shp = glob(f\"shapes/{shape_dir}/*.shp\")[0] # このコードの場所からみた住所のshpファイルの相対パス\n",
        "shape_file = path_home + address_shp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QVzgY8L4r5K",
        "outputId": "64c83b7d-5b91-4ff0-dcc8-406988a7fd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plateauutils\n",
            "  Downloading plateauutils-0.0.14-py3-none-any.whl (414 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/414.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/414.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.4/414.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from plateauutils) (8.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from plateauutils) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from plateauutils) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from plateauutils) (9.4.0)\n",
            "Collecting py3dtiles (from plateauutils)\n",
            "  Downloading py3dtiles-7.0.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyproj in /usr/local/lib/python3.10/dist-packages (from plateauutils) (3.6.1)\n",
            "Collecting reearthcmsapi (from plateauutils)\n",
            "  Downloading reearthcmsapi-0.0.3-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from plateauutils) (2.31.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from plateauutils) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from plateauutils) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->plateauutils) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->plateauutils) (2023.3.post1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from py3dtiles->plateauutils) (3.0.8)\n",
            "Collecting earcut==1.1.5 (from py3dtiles->plateauutils)\n",
            "  Downloading earcut-1.1.5.tar.gz (9.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lz4 (from py3dtiles->plateauutils)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from py3dtiles->plateauutils) (0.58.1)\n",
            "Collecting numpy (from plateauutils)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py3dtiles->plateauutils) (5.9.5)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from py3dtiles->plateauutils) (23.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj->plateauutils) (2023.11.17)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from reearthcmsapi->plateauutils) (2.4.0)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from reearthcmsapi->plateauutils) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from reearthcmsapi->plateauutils) (4.5.0)\n",
            "Requirement already satisfied: urllib3<2.1.0,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from reearthcmsapi->plateauutils) (2.0.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->plateauutils) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->plateauutils) (3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->plateauutils) (1.16.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->py3dtiles->plateauutils) (0.41.1)\n",
            "Building wheels for collected packages: earcut\n",
            "  Building wheel for earcut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for earcut: filename=earcut-1.1.5-py3-none-any.whl size=8738 sha256=d43aebe87a45c0b80f7888aeeba6f9aee123468b4d72c7f60b51842599f3a58b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/44/c4/ae3b04eee88104a19850c1cbc658fa398560c35ba5956faa79\n",
            "Successfully built earcut\n",
            "Installing collected packages: numpy, lz4, reearthcmsapi, earcut, py3dtiles, plateauutils\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed earcut-1.1.5 lz4-4.3.3 numpy-1.26.3 plateauutils-0.0.14 py3dtiles-7.0.0 reearthcmsapi-0.0.3\n",
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.3\n",
            "    Uninstalling numpy-1.26.3:\n",
            "      Successfully uninstalled numpy-1.26.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n",
            "Collecting scipy==1.11.3\n",
            "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy==1.11.3) (1.26.0)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.11.3\n",
            "Collecting scikit-image==0.22.0\n",
            "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (1.26.0)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (3.2.1)\n",
            "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (2023.12.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (23.2)\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image==0.22.0) (0.3)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "Successfully installed scikit-image-0.22.0\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.11.17)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.0)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.9 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "# @title 主要ライブラリインポート\n",
        "#!pip install git+https://github.com/eukarya-inc/plateauutils.git@main#egg=plateauutils\n",
        "\n",
        "!pip install plateauutils\n",
        "!pip install numpy==1.26.0\n",
        "!pip install scipy==1.11.3\n",
        "!pip install scikit-image==0.22.0\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from progressbar import progressbar\n",
        "from shapely.geometry import MultiPolygon, shape, mapping, Point\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "from rasterio.features import geometry_mask\n",
        "import fiona\n",
        "import csv\n",
        "import sys\n",
        "import shutil\n",
        "from plateauutils.flood_converter.flood_to_png import FloodToPng\n",
        "#sys.path.append(path_home)\n",
        "import plateau_floodsar_lib as pfsl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip list"
      ],
      "metadata": {
        "id": "4fBPoSrLLlA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUrBuR1IqzZB",
        "outputId": "b9b9630a-66b4-4529-e07b-71de07fd36f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90455\n"
          ]
        }
      ],
      "source": [
        "# JSONファイルからデータを読み込む\n",
        "with open(json_buildings, 'r') as f:\n",
        "    buildings = json.load(f)\n",
        "\n",
        "print(len(buildings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGBvIoZAWg7",
        "outputId": "ce1fb74f-2b15-4750-8671-23194366e58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'gid': 'bldg_5bb0e545-ec27-4bdd-b4f5-ce88ac0802f0', 'center': [130.39681017603277, 33.00481616943035], 'min_height': 3.251, 'measured_height': None, 'building_structure_type': None, 'dem': nan}, {'gid': 'bldg_223b2a8f-c2f4-4d06-bfe9-b7795ebd9d9a', 'center': [130.3963708808834, 33.00190456995042], 'min_height': 5.253, 'measured_height': 2.6, 'building_structure_type': None, 'dem': 5.522831106867581}, {'gid': 'bldg_5b497c2a-fb59-424b-ac81-2d9c8355f5ed', 'center': [130.39730104480077, 33.00499391435827], 'min_height': 3.057, 'measured_height': None, 'building_structure_type': None, 'dem': 2.5878461692023644}, {'gid': 'bldg_3b3417a5-f869-4420-95f9-c1d6cbf30c9d', 'center': [130.3986860225292, 33.00550176708172], 'min_height': 2.657, 'measured_height': 2.1, 'building_structure_type': None, 'dem': 2.610875161877514}, {'gid': 'bldg_c06324bb-f540-4309-a779-8c428bfd84e5', 'center': [130.3996265232932, 33.00239327178217], 'min_height': 5.499, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.131970960710376}, {'gid': 'bldg_0ede5d15-3637-4cb2-b452-faed8c8236c3', 'center': [130.39964145640266, 33.00235875262421], 'min_height': 5.5, 'measured_height': 2.5, 'building_structure_type': None, 'dem': 5.1195241592127285}, {'gid': 'bldg_abb7ba9f-923f-40de-9c99-b3321b8dbd3c', 'center': [130.399391314812, 33.0023375216338], 'min_height': 5.499, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.0988511735267075}, {'gid': 'bldg_ded59a34-8656-4baf-bef8-bd4570559fa5', 'center': [130.39965294971702, 33.00232250098261], 'min_height': 5.5, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.093607092355062}, {'gid': 'bldg_6241c153-d639-426e-b727-e1e214fcba28', 'center': [130.39939976565594, 33.00230225889832], 'min_height': 5.429, 'measured_height': 2.6, 'building_structure_type': None, 'dem': 5.0967573036610085}, {'gid': 'bldg_2ae6bcc2-b910-4c2b-af1f-da64bf716ed5', 'center': [130.3994120239776, 33.00226353995445], 'min_height': 5.413, 'measured_height': 3.2, 'building_structure_type': None, 'dem': 5.089342996982695}]\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  print(buildings[0:10])\n",
        "  print(len([vv for vv in buildings if vv[\"measured_height\"] <2.1]))\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiiNoHhpLoSh",
        "outputId": "c7fe5b3f-13a5-432f-f733-e1d4d45831b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'レンガ造・コンクリートブロック造・石造', '鉄骨鉄筋コンクリート造', '木造・土蔵造', '鉄骨造', None, '鉄筋コンクリート造', '軽量鉄骨造'}\n"
          ]
        }
      ],
      "source": [
        "building_types = set([vv[\"building_structure_type\"] for vv in buildings])\n",
        "print(building_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtRRGyGWHQ8U"
      },
      "outputs": [],
      "source": [
        "#depth_map = np.load(file_flooddepth.format(int(maxdepth*100)))\n",
        "dem_map = np.load(file_flooddem.format(int(maxdepth*100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0eAcGhZNhen"
      },
      "outputs": [],
      "source": [
        "#lons = depth_map[\"lons\"]\n",
        "#lats = depth_map[\"lats\"]\n",
        "#depthmap = depth_map[\"floodmap_depth\"]\n",
        "lons = dem_map[\"lons\"]\n",
        "lats = dem_map[\"lats\"]\n",
        "demmap = dem_map[\"floodmap_dem\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa4AkcK4bEd6",
        "outputId": "0d66d6fc-d975-46ab-e097-8f007b3b429a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[130.37475586 130.37479877 130.37484169 ... 130.55040836 130.55045128\n",
            " 130.55049419]\n",
            "[33.10989377 33.1098578  33.10982183 ... 32.99028909 32.99025312\n",
            " 32.99021715]\n"
          ]
        }
      ],
      "source": [
        "#np.set_printoptions(threshold=np.inf)\n",
        "print(lons)\n",
        "print(lats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txTJoLBRHRsG",
        "outputId": "e27f7afa-21ea-4b84-8291-82e4e06f5c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]]\n"
          ]
        }
      ],
      "source": [
        "print(demmap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zud6DaQKNeY5"
      },
      "outputs": [],
      "source": [
        "if flg_checkDisp:\n",
        "  ax =plt.subplot(1,1,1)\n",
        "  #img = ax.contourf(lons,lats, depthmap,levels=np.arange(0,maxdepth+0.1,0.25))\n",
        "  img = ax.contourf(lons,lats, demmap)#,levels=np.arange(0,maxdepth+0.1,0.25))\n",
        "  ax.axis(\"equal\")\n",
        "  plt.colorbar(img)\n",
        "  #ax.set_xlim(130.4,130.5)\n",
        "  #ax.set_ylim(33.22,33.32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l13mzBAu9NZ8"
      },
      "outputs": [],
      "source": [
        "bldgtype_yukaue_depth = {\"木造・土蔵造\":0.45, \"レンガ造・コンクリートブロック造・石造\":0.45, \"不明\":0.45}\n",
        "bldgtype_mokuzou = [\"木造・土蔵造\"]\n",
        "bldgtype_renga = [\"レンガ造・コンクリートブロック造・石造\"]\n",
        "def get_floodcategory(bldg_type, depth):\n",
        "  min_depth = 0\n",
        "  if bldg_type in bldgtype_yukaue_depth:\n",
        "    min_depth = bldgtype_yukaue_depth[bldg_type]\n",
        "  elif bldg_type is None:\n",
        "    min_depth = 0.45\n",
        "  category = \"非浸水\"\n",
        "  if depth is not None and depth >0:\n",
        "    if depth > min_depth :\n",
        "      if min_depth == 0:\n",
        "        category = \"浸水\"\n",
        "      else:\n",
        "        category = \"床上\"\n",
        "    elif depth > 0:\n",
        "      category = \"床下\"\n",
        "  if bldg_type in bldgtype_mokuzou:\n",
        "    category += \"（木造）\"\n",
        "  elif bldg_type in bldgtype_renga:\n",
        "    category += \"（レンガ造）\"\n",
        "  elif bldg_type == \"不明\" or bldg_type is None:\n",
        "    category += \"（不明）\"\n",
        "  else:\n",
        "    category += \"（非木造）\"\n",
        "  return category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg8jRMBW9oEH",
        "outputId": "e06ce48e-d806-4422-ffa5-f10894e41469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "床上（木造）\n",
            "床下（木造）\n",
            "床上（不明）\n",
            "床下（不明）\n",
            "浸水（非木造）\n",
            "非浸水（不明）\n",
            "非浸水（不明）\n"
          ]
        }
      ],
      "source": [
        "print(get_floodcategory(\"木造・土蔵造\", 1) )\n",
        "print(get_floodcategory(\"木造・土蔵造\", 0.2) )\n",
        "print(get_floodcategory(\"不明\", 1) )\n",
        "print(get_floodcategory(\"不明\", 0.3) )\n",
        "print(get_floodcategory(\"非木造\", 1) )\n",
        "print(get_floodcategory(None, -1) )\n",
        "print(get_floodcategory(None, None) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is3Ht14DOJaB"
      },
      "outputs": [],
      "source": [
        "def calc_floatIdx_of_list(val:float, list):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      val (float): value which the method finds index for.\n",
        "      list (array-like): must be ordered (ascending or descending)\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if list[0] < list[-1]:\n",
        "      idl = np.where(val > list)[0][-1]\n",
        "    else:\n",
        "      idl = np.where(val < list)[0][-1]\n",
        "  except IndexError:\n",
        "    print(\"IndexErrorCheck:\", val, (list[0], list[-1]))\n",
        "    return np.nan\n",
        "  if idl == len(list) -1:\n",
        "    return idl\n",
        "  return idl + (val-list[idl])/(list[idl+1]-list[idl])\n",
        "  #return (val - list[0])/(list[-1]-list[0]) * (len(list)-1)\n",
        "\n",
        "def calc_interpval_of_list(idx:float, list):\n",
        "  il = int(idx)\n",
        "  ih = int(idx + 1)\n",
        "  if ih >= len(list):\n",
        "    return list[-1]\n",
        "  dd = idx - il\n",
        "  return (1-dd)*list[il] + dd*list[ih]\n",
        "\n",
        "def calc_InterpVal_lonlat(lon, lat, data, lons, lats):\n",
        "  #print(\"Check1: \", lon, lat)\n",
        "  cx = calc_floatIdx_of_list(lon, lons)\n",
        "  cy = calc_floatIdx_of_list(lat, lats)\n",
        "  #print(\"Check: \", cx, cy, \"\\n\")\n",
        "  if np.any(np.isnan([cy, cx])):\n",
        "    return np.nan\n",
        "  xl = int(cx)\n",
        "  yl = int(cy)\n",
        "  xh = xl + 1\n",
        "  dx = cx-xl\n",
        "  yh = yl + 1\n",
        "  dy = cy - yl\n",
        "  if xh > len(lons)-1:\n",
        "    xh = xl\n",
        "  if yh > len(lats)-1:\n",
        "    yh = yl\n",
        "  val_ll = data[yl,xl]\n",
        "  val_hl = data[yh,xl]\n",
        "  val_lh = data[yl,xh]\n",
        "  val_hh = data[yh, xh]\n",
        "  return (1-dy)*(1-dx)*val_ll + (1-dy)*dx*val_lh + dy*(1-dx)*val_hl + dy*dx*val_hh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbFVHhi5vOep",
        "outputId": "4e95a5b2-1215-423a-925d-c2905ba6b810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130.374755859375 130.55049419403076\n",
            "33.109893770453134 32.99021715139026\n"
          ]
        }
      ],
      "source": [
        "print(lons[0], lons[-1])\n",
        "print(lats[0], lats[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ym-qxoGVZu8H"
      },
      "outputs": [],
      "source": [
        "#@title 住所付与の準備\n",
        "\n",
        "# shpファイルのパス\n",
        "\n",
        "# マルチポリゴンのバウンディングボックスを取得します。\n",
        "minx, miny, maxx, maxy = lons.min(), lats.min(), lons.max(), lats.max() # [130.412497, 33.224723, 130.68759971, 33.40869805]\n",
        "# ラスタライズのパラメータを設定します。\n",
        "raster_height, raster_width = demmap.shape # (5376, 6656)\n",
        "\n",
        "transform = rasterio.transform.from_origin(minx, maxy, (maxx-minx)/raster_width, (maxy-miny)/raster_height)\n",
        "\n",
        "lookup_table = []\n",
        "\n",
        "# shpファイルを開く\n",
        "with fiona.open(shape_file, 'r') as src:\n",
        "    with rasterio.MemoryFile() as memfile:\n",
        "        with memfile.open(driver='GTiff',\n",
        "                          height=raster_height,\n",
        "                          width=raster_width,\n",
        "                          count=1,\n",
        "                          dtype='uint8',\n",
        "                          crs=src.crs,\n",
        "                          transform=transform) as dataset:\n",
        "            combined_mask = np.empty((dataset.height, dataset.width))\n",
        "            combined_mask[:] = np.nan\n",
        "            for i, feature in enumerate(src):\n",
        "                # 各フィーチャからジオメトリを取得し、shapelyオブジェクトに変換\n",
        "                polygon = shape(feature['geometry'])\n",
        "                mask = geometry_mask([mapping(polygon)],\n",
        "                                      transform=dataset.transform,\n",
        "                                      invert=True,\n",
        "                                      out_shape=(dataset.height, dataset.width))\n",
        "                combined_mask[mask] = i\n",
        "                del mask\n",
        "\n",
        "                # PREF_NAME 福岡県\n",
        "                # CITY_NAME 久留米市\n",
        "                # S_NAME 花畑三丁目\n",
        "                pref_name = feature[\"properties\"][\"PREF_NAME\"]\n",
        "                city_name = feature[\"properties\"][\"CITY_NAME\"]\n",
        "                s_name = feature[\"properties\"][\"S_NAME\"]\n",
        "                lookup_table.append({\n",
        "                    \"id\": i,\n",
        "                    \"address\": s_name,\n",
        "                    \"vector\": polygon\n",
        "                })\n",
        "\n",
        "\n",
        "#plt.imshow(combined_mask)\n",
        "\n",
        "new_lons = np.linspace(lons.min(), lons.max(), raster_width)  # 経度\n",
        "new_lats = np.linspace(lats.max(), lats.min(), raster_height)   # 緯度\n",
        "\n",
        "def get_address_ids(lon, lat, combined_mask):\n",
        "    #center_lon, center_lat = building['center']\n",
        "\n",
        "    # 緯度経度からピクセル座標に変換\n",
        "    #lons_to_pixel = np.searchsorted(lons, center_lon) - 1\n",
        "    #lats_to_pixel = np.searchsorted(lats, center_lat) - 1\n",
        "    lons_to_pixel = int(calc_floatIdx_of_list(lon, new_lons))\n",
        "    lats_to_pixel = int(calc_floatIdx_of_list(lat, new_lats))\n",
        "\n",
        "    # # 周囲のセルを調べるための正規分布を作成\n",
        "    # x, y = np.meshgrid(np.arange(combined_mask.shape[1]), np.arange(combined_mask.shape[0]))\n",
        "    # pos = np.dstack((x, y))\n",
        "    # rv = multivariate_normal([lons_to_pixel, lats_to_pixel], [[1.22, 0], [0, 1.22]])\n",
        "    # gaussian_mask = rv.pdf(pos)\n",
        "\n",
        "    # # 正規分布からしきい値を超えるセルのIDを取得\n",
        "    # # threshold = gaussian_mask.mean()\n",
        "    # # ids = combined_mask[gaussian_mask > threshold]\n",
        "\n",
        "    ids = combined_mask[lats_to_pixel-1:lats_to_pixel+2, lons_to_pixel-1:lons_to_pixel+2] # 中心と周囲8ピクセルを見る\n",
        "    unique_ids = np.unique(ids[~np.isnan(ids)])  # np.nanを除外してユニークなIDを取得\n",
        "\n",
        "    return unique_ids\n",
        "\n",
        "def find_address(lon, lat, combined_mask):\n",
        "      address_ids = get_address_ids(lon, lat, combined_mask)\n",
        "      address = \"\"\n",
        "      if len(address_ids) == 0:\n",
        "          address = '不明'\n",
        "      elif len(address_ids) == 1:\n",
        "          address = lookup_table[int(address_ids[0])]['address']\n",
        "      else:\n",
        "          # 複数のIDがある場合の処理\n",
        "          # lookup_tableのベクトルと照合して正しいIDを見つける処理\n",
        "          center_point =  Point(lon, lat) # Point(building['center'][0], building['center'][1])\n",
        "          possible_addresses = []\n",
        "\n",
        "          for address_id in address_ids:\n",
        "              for entry in lookup_table:\n",
        "                  if entry['id'] == address_id:\n",
        "                      polygon = shape(entry['vector'])\n",
        "                      if polygon.contains(center_point):\n",
        "                          possible_addresses.append(entry['address'])\n",
        "                          break  # 最初にマッチしたアドレスでループを抜ける\n",
        "\n",
        "          if possible_addresses:\n",
        "              address = possible_addresses[0]  # 最初に見つかった住所を採用\n",
        "          else:\n",
        "              # どのポリゴンにも含まれなかったら周囲の住所を全て列挙\n",
        "              address = \" / \".join([entry['address'] for entry in lookup_table if entry['id'] in address_ids])\n",
        "      return address\n",
        "\n",
        "# 処理を実行\n",
        "#buildings_with_address = assign_address(buildings, combined_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXsl3QJ-q16O",
        "outputId": "bc5110e1-4b82-4c8b-d345-9ed035dbe538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (90455 of 90455) |##################| Elapsed Time: 0:00:25 Time:  0:00:25\n"
          ]
        }
      ],
      "source": [
        "for bb in progressbar(buildings):\n",
        "  lon, lat = bb[\"center\"]\n",
        "  #print(lon, lat)\n",
        "  #depth = calc_InterpVal_lonlat(lon, lat, depthmap, lons, lats)\n",
        "  dem = calc_InterpVal_lonlat(lon, lat, demmap, lons, lats)\n",
        "  depth = depthfactor * (dem - bb[\"min_height\"]) #  bb[\"dem\"]\n",
        "  bb[\"lon\"] = bb[\"center\"][0]\n",
        "  bb[\"lat\"] = bb[\"center\"][1]\n",
        "  #print(depth)\n",
        "  bb[\"out\"] = False\n",
        "  bb[\"flood_category\"] = get_floodcategory(bb[\"building_structure_type\"], depth)\n",
        "  bb[\"depth\"] = depth\n",
        "  if \"非浸水\" in bb[\"flood_category\"]:\n",
        "    bb[\"out\"] = True\n",
        "    bb[\"depth\"] = None\n",
        "  bb[\"address\"] = find_address(lon,lat,combined_mask)\n",
        "  if \"uro:realEstateIDOfBuilding\" not in bb:\n",
        "    if flg_dummy_realEstateID:\n",
        "      bb[\"uro:realEstateIDOfBuilding\"] = \"{0:013d}-0000\".format(int(\"0x\"+bb[\"gid\"][-12:],0) % 10**14)\n",
        "    else:\n",
        "      bb[\"uro:realEstateIDOfBuilding\"] = None\n",
        "  if \"uro:realEstateIDOfBuildingUnitOwnership\" not in bb:\n",
        "    if flg_dummy_realEstateID:\n",
        "      bb[\"uro:realEstateIDOfBuildingUnitOwnership\"] = \"{0:013d}-0000\".format(int(\"0x\"+bb[\"gid\"][-12:],0) % 10**14)\n",
        "    else:\n",
        "      bb[\"uro:realEstateIDOfBuildingUnitOwnership\"] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ctqOEB5z3P-",
        "outputId": "3d972acd-7556-4f8c-a7db-c77c2e08d082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1m未満： 3400\n",
            "[{'gid': 'bldg_5bb0e545-ec27-4bdd-b4f5-ce88ac0802f0', 'center': [130.39681017603277, 33.00481616943035], 'min_height': 3.251, 'measured_height': None, 'building_structure_type': None, 'dem': nan, 'lon': 130.39681017603277, 'lat': 33.00481616943035, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '27086397080304-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '27086397080304-0000'}, {'gid': 'bldg_223b2a8f-c2f4-4d06-bfe9-b7795ebd9d9a', 'center': [130.3963708808834, 33.00190456995042], 'min_height': 5.253, 'measured_height': 2.6, 'building_structure_type': None, 'dem': 5.522831106867581, 'lon': 130.3963708808834, 'lat': 33.00190456995042, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '1731908410778-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '1731908410778-0000'}, {'gid': 'bldg_5b497c2a-fb59-424b-ac81-2d9c8355f5ed', 'center': [130.39730104480077, 33.00499391435827], 'min_height': 3.057, 'measured_height': None, 'building_structure_type': None, 'dem': 2.5878461692023644, 'lon': 130.39730104480077, 'lat': 33.00499391435827, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '50150241596909-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '50150241596909-0000'}, {'gid': 'bldg_3b3417a5-f869-4420-95f9-c1d6cbf30c9d', 'center': [130.3986860225292, 33.00550176708172], 'min_height': 2.657, 'measured_height': 2.1, 'building_structure_type': None, 'dem': 2.610875161877514, 'lon': 130.3986860225292, 'lat': 33.00550176708172, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '13128288865437-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '13128288865437-0000'}, {'gid': 'bldg_c06324bb-f540-4309-a779-8c428bfd84e5', 'center': [130.3996265232932, 33.00239327178217], 'min_height': 5.499, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.131970960710376, 'lon': 130.3996265232932, 'lat': 33.00239327178217, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '54217444377829-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '54217444377829-0000'}, {'gid': 'bldg_0ede5d15-3637-4cb2-b452-faed8c8236c3', 'center': [130.39964145640266, 33.00235875262421], 'min_height': 5.5, 'measured_height': 2.5, 'building_structure_type': None, 'dem': 5.1195241592127285, 'lon': 130.39964145640266, 'lat': 33.00235875262421, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '75898171537091-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '75898171537091-0000'}, {'gid': 'bldg_abb7ba9f-923f-40de-9c99-b3321b8dbd3c', 'center': [130.399391314812, 33.0023375216338], 'min_height': 5.499, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.0988511735267075, 'lon': 130.399391314812, 'lat': 33.0023375216338, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '97027792010556-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '97027792010556-0000'}, {'gid': 'bldg_ded59a34-8656-4baf-bef8-bd4570559fa5', 'center': [130.39965294971702, 33.00232250098261], 'min_height': 5.5, 'measured_height': 3.1, 'building_structure_type': None, 'dem': 5.093607092355062, 'lon': 130.39965294971702, 'lat': 33.00232250098261, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '8105935052709-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '8105935052709-0000'}, {'gid': 'bldg_6241c153-d639-426e-b727-e1e214fcba28', 'center': [130.39939976565594, 33.00230225889832], 'min_height': 5.429, 'measured_height': 2.6, 'building_structure_type': None, 'dem': 5.0967573036610085, 'lon': 130.39939976565594, 'lat': 33.00230225889832, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '48361130965544-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '48361130965544-0000'}, {'gid': 'bldg_2ae6bcc2-b910-4c2b-af1f-da64bf716ed5', 'center': [130.3994120239776, 33.00226353995445], 'min_height': 5.413, 'measured_height': 3.2, 'building_structure_type': None, 'dem': 5.089342996982695, 'lon': 130.3994120239776, 'lat': 33.00226353995445, 'out': True, 'flood_category': '非浸水（不明）', 'depth': None, 'address': '新港町', 'uro:realEstateIDOfBuilding': '40126243466965-0000', 'uro:realEstateIDOfBuildingUnitOwnership': '40126243466965-0000'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"2.1m未満：\", len([bb for bb in buildings if bb[\"measured_height\"] is None or bb[\"measured_height\"] < 2.1]))\n",
        "print([bb for bb in buildings if \"非浸水\" in bb[\"flood_category\"]][0:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flood_categories = set([vv[\"flood_category\"] for vv in buildings])\n",
        "print(flood_categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uQ8W2hUboxe",
        "outputId": "76c3da88-8bbd-4ee8-c20e-f228da044f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'床下（レンガ造）', '非浸水（木造）', '床上（不明）', '床上（木造）', '床上（レンガ造）', '床下（木造）', '床下（不明）', '浸水（非木造）', '非浸水（不明）', '非浸水（レンガ造）', '非浸水（非木造）'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDrixPRnyAwG",
        "outputId": "871d63c3-1e97-4063-b9a1-e17961423f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13141 ( 527 )/ 90455\n"
          ]
        }
      ],
      "source": [
        "num_flooded = len([bb for bb in buildings if not bb[\"out\"]])\n",
        "num_yukashita = len([bb for bb in buildings if \"床下\" in bb[\"flood_category\"]])\n",
        "\n",
        "print(num_flooded,\"(\",num_yukashita,\")/\",len(buildings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HCz1FLLGxrJ"
      },
      "outputs": [],
      "source": [
        "if flg_checkDisp:\n",
        "  xx = [bb[\"center\"][0] for bb in buildings]\n",
        "  yy = [bb[\"center\"][1] for bb in buildings]\n",
        "  cc = [\"orangered\" if not bb[\"out\"] else \"purple\" for bb in buildings]\n",
        "  ss = [1 if not bb[\"out\"] else 0.1 for bb in buildings]\n",
        "  aa = [1 if not bb[\"out\"] else 0.01 for bb in buildings]\n",
        "  ax =plt.subplot(1,1,1)\n",
        "  #img = ax.contourf(lons,lats, depthmap,levels=np.arange(0,maxdepth+0.1,0.25))\n",
        "  img = ax.contourf(lons,lats, demmap)#,levels=np.arange(0,maxdepth+0.1,0.25))\n",
        "  plt.scatter(xx,yy,c=cc,s=ss)#, alpha=aa)\n",
        "  ax.axis(\"equal\")\n",
        "  #plt.xlim([130.50, 130.53])\n",
        "  #plt.ylim([33.32, 33.34])\n",
        "  plt.colorbar(img)\n",
        "  plt.scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivAoyw0GmEms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f9d09b-a02d-48a5-c7fb-168e73d3514f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/omuta-r2-giaj/ForUpload/’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir {path_upload}\n",
        "csv_keylist = ['gid', 'lon', 'lat', 'min_height', 'flood_category','depth', 'address', 'uro:realEstateIDOfBuilding','uro:realEstateIDOfBuildingUnitOwnership']\n",
        "csv_header = ['gid', 'lon', 'lat', 'dem', 'flood_category','flood_depth', 'address', 'real_estate_id_of_building','real_estate_id_of_building_unit_ownership']\n",
        "with open(file_building_csv, \"w\") as ofile:\n",
        "  ofile.write(\",\".join(f\"'{w}'\" for w in csv_header)+\"\\n\")\n",
        "  for bb in buildings:\n",
        "    tempstr = \"\"\n",
        "    for kk in csv_keylist:\n",
        "      if isinstance(bb[kk], str):\n",
        "        tempstr += f\"'{bb[kk]}',\"\n",
        "      else:\n",
        "        tempstr += f\"{bb[kk]},\"\n",
        "    ofile.write(tempstr[:-1]+\"\\n\")\n",
        "    #print(tempstr[:-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lons,lats)\n",
        "print(lons[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1HOGtOZzU5I",
        "outputId": "927ef87c-5a85-44b6-9919-a45d44a4f7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[130.37475586 130.37479877 130.37484169 ... 130.55040836 130.55045128\n",
            " 130.55049419] [33.10989377 33.1098578  33.10982183 ... 32.99028909 32.99025312\n",
            " 32.99021715]\n",
            "130.55049419403076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dump2heatmap(lons, lats, buildings):\n",
        "  gauss_hl = 63\n",
        "  xx, yy = np.meshgrid(np.arange(-gauss_hl,gauss_hl+1),np.arange(-gauss_hl,gauss_hl+1))\n",
        "  #gauss = 1/(2045*np.pi)*np.exp(-(xx**2+yy**2)/2048) # sigma = 32 px\n",
        "  gauss = np.sqrt((xx**2+yy**2)) <= 31 #gauss_hl\n",
        "  #print(np.shape(gauss))\n",
        "  maxx = len(lons)-1\n",
        "  maxy = len(lats)-1\n",
        "  heatmap = np.zeros((maxy+1, maxx+1))\n",
        "  #print(np.shape(gauss))\n",
        "  print(f\"dumping {len(buildings)} cases\")\n",
        "  for bb in buildings:\n",
        "    lon, lat = bb[\"center\"]\n",
        "    idx = int(calc_floatIdx_of_list(lon, lons))\n",
        "    idy = int(calc_floatIdx_of_list(lat, lats))\n",
        "    gxl, gxh = 0, gauss_hl*2\n",
        "    gyl, gyh = 0, gauss_hl*2\n",
        "    idxl, idxh = idx-gauss_hl, idx+gauss_hl\n",
        "    idyl, idyh = idy-gauss_hl, idy+gauss_hl\n",
        "    if idxl < 0:\n",
        "      gxl = - idxl\n",
        "      idxl = 0\n",
        "    if idxh > maxx:\n",
        "      gxh -= idxh - maxx\n",
        "      idxh = maxx\n",
        "    if idyl < 0:\n",
        "      gyl = - idyl\n",
        "      idyl = 0\n",
        "    if idyh > maxy:\n",
        "      gyh -= idyh - maxy\n",
        "      idyh = maxy\n",
        "    #print(idyl,idyh,idxl,idxh,gyl,gyh,gxl,gxh)\n",
        "    try:\n",
        "      heatmap[idyl:idyh+1,idxl:idxh+1] += gauss[gyl:gyh+1,gxl:gxh+1]\n",
        "    except ValueError as e:\n",
        "      print(idyl,idyh,idxl,idxh)\n",
        "      print(gyl,gyh,gxl,gxh)\n",
        "      raise e\n",
        "  return heatmap/(np.sum(gauss)*16) * 10000"
      ],
      "metadata": {
        "id": "1vlQiytQ2OH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lons))\n",
        "print(len(lats))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvGm9uRcPDij",
        "outputId": "e44c5557-6626-4716-bd80-9e91b4b8c399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n",
            "3328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yukaue_mokuzou = dump2heatmap(lons, lats, [bb for bb in buildings if bb[\"flood_category\"]==\"床上（木造）\"])\n",
        "yukashita_mokuzou = dump2heatmap(lons, lats, [bb for bb in buildings if bb[\"flood_category\"]==\"床下（木造）\"])\n",
        "all_mokuzou = dump2heatmap(lons, lats, [bb for bb in buildings if \"（木造）\" in bb[\"flood_category\"]])"
      ],
      "metadata": {
        "id": "2WR-HY26HO-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31500a9-27b4-4ddb-aeec-6fd6e2db99e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dumping 5529 cases\n",
            "dumping 268 cases\n",
            "dumping 38267 cases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.nansum(yukaue_mokuzou))\n",
        "print(np.nansum(yukashita_mokuzou))\n",
        "print(np.nansum(all_mokuzou))\n",
        "print(len([bb for bb in buildings if bb[\"building_structure_type\"] == \"木造・土蔵造\"]))"
      ],
      "metadata": {
        "id": "mW59wwSfpvx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a2fa95-9d55-4df3-f238-cbf603fd6a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3455625.0000000014\n",
            "167499.99999999988\n",
            "23916875.00000001\n",
            "38267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if flg_checkDisp:\n",
        "  chech_heatmap = all_mokuzou\n",
        "  ax =plt.subplot(1,1,1)\n",
        "  plt_dens = np.copy(chech_heatmap)\n",
        "  plt_dens[chech_heatmap==0] = np.nan\n",
        "  img = ax.pcolormesh(lons,lats, plt_dens)\n",
        "  ax.axis(\"equal\")\n",
        "  #plt.xlim([130.50, 130.53])\n",
        "  #plt.ylim([33.32, 33.34])\n",
        "  plt.colorbar(img)"
      ],
      "metadata": {
        "id": "fH3-HcOh1TNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title XYZタイル分けされた点郡NPZファイルの生成関数\n",
        "#print(len(lats)/256.0, len(lons)/256.0)\n",
        "\n",
        "def save_tile_npz(lats,lons,map, classificationmap, zoom=15, dst_dir =\"temp/\"):\n",
        "  dir_zoom = dst_dir + f\"{zoom}/\"\n",
        "  if not os.path.exists(dir_zoom):\n",
        "    os.makedirs(dir_zoom)\n",
        "  res_lons = np.array([])\n",
        "  res_lats = np.array([])\n",
        "  res_maps = np.array([])\n",
        "  res_class = np.array([])\n",
        "  print(f\" / total loop num: {len(lats)/256}\")\n",
        "  for jj, tmp_lat in progressbar(enumerate(lats[::256])):\n",
        "    idj = jj*256\n",
        "    sublats = lats[idj:idj+256]\n",
        "    for ii, tmp_lon in enumerate(lons[::256]):\n",
        "      idi = ii*256\n",
        "      sublons = lons[idi:idi+256]\n",
        "      xx,yy  = pfsl.calc_xyz_from_lonlat(tmp_lon, tmp_lat, zoom)\n",
        "      #print(ii,jj, xx, yy)\n",
        "      submap = map[idj:idj+256,idi:idi+256]\n",
        "      subclass = classificationmap[idj:idj+256,idi:idi+256]\n",
        "      grd_lons, grd_lats  = np.meshgrid(sublons,sublats)\n",
        "      flt_lons = grd_lons.ravel()\n",
        "      flt_lats = grd_lats.ravel()\n",
        "      flt_map = submap.ravel()\n",
        "      flt_class = subclass.ravel()\n",
        "      #selected = [[lon,lat,dem] for lon, lat, dem in zip(flt_lons, flt_lats,flt_map) if not np.isnan(dem)]\n",
        "      #print(flt_lons[0:5])\n",
        "      #print(flt_lats[0:5])\n",
        "      #print(flt_map[0:5])\n",
        "      #print(ii, jj, f\"{subzoom}-{xx}-{yy}\", f\"{subzoom}-{chk_tile[0]}-{chk_tile[1]}\")\n",
        "      if not os.path.exists(f\"{dir_zoom}{xx}\"):\n",
        "        os.mkdir(f\"{dir_zoom}{xx}\")\n",
        "      np.savez(f\"{dir_zoom}{xx}/{yy}.npz\", lons=flt_lons, lats=flt_lats, dem=flt_map, classification=flt_class)\n",
        "      res_lons = np.append(res_lons, flt_lons)\n",
        "      res_lats = np.append(res_lats, flt_lats)\n",
        "      res_maps = np.append(res_maps, flt_map)\n",
        "      res_class = np.append(res_class, flt_class)\n",
        "  return res_lons, res_lats, res_maps, res_class\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ibvWUGuWNgXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "worklist = [\n",
        "  [yukaue_mokuzou, file_floodHeattile_yukauemokuzou_zip],\n",
        "  [yukashita_mokuzou, file_floodHeattile_yukashitamokuzou_zip],\n",
        "  [all_mokuzou, file_floodHeattile_allmokuzou_zip]\n",
        "]\n",
        "for heatmap, savefile in worklist:\n",
        "  print(f\"for {savefile}\")\n",
        "  #print(np.nansum(heatmap))\n",
        "  category = np.zeros_like(heatmap)\n",
        "  levels = [5, 10, 15, 20, 25]\n",
        "  for ii, ll in enumerate(levels[::-1]):\n",
        "    category[heatmap<ll] = len(levels)-ii\n",
        "  category[heatmap==0] = 0\n",
        "  category[heatmap>levels[-1]] = len(levels)+1\n",
        "  heatmap[heatmap==0] = np.nan\n",
        "  if os.path.exists(\"/heat_tmp\"):\n",
        "    !rm -rf /heat_tmp\n",
        "  test_lons, test_lats, test_maps, test_class = save_tile_npz(lats,lons,heatmap,category,dst_dir=\"/heat_tmp/\")\n",
        "  if os.path.exists(\"/heattile_tmp/\"):\n",
        "    !rm -rf /heattile_tmp\n",
        "  p = FloodToPng(\"/heat_tmp/\")\n",
        "  p.parse(\"/heattile_tmp/\")\n",
        "  shutil.make_archive(savefile[:-4], 'zip', \"/heattile_tmp/\")\n",
        "  #!rm -rf \"heat_tmp\"\n",
        "  #!rm -rf \"heattile_tmp\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKMn31TlNiol",
        "outputId": "14ebc27c-b97e-461a-f02a-fc30e3c96815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for /content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/omuta-r2-giaj/ForUpload/heatmap_yukaue_mokuzou.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r/ |#                                                  | 0 Elapsed Time: 0:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " / total loop num: 13.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "| |    #                                             | 12 Elapsed Time: 0:00:19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for /content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/omuta-r2-giaj/ForUpload/heatmap_yukashita_mokuzou.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "- | #                                                 | 1 Elapsed Time: 0:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " / total loop num: 13.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "| |        #                                         | 12 Elapsed Time: 0:00:19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for /content/drive/MyDrive/plateau-2023-uc01-satellite-analytics/PLATEAU-FloodSAR/omuta-r2-giaj/ForUpload/heatmap_all_mokuzou.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "- | #                                                 | 1 Elapsed Time: 0:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " / total loop num: 13.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "| |          #                                       | 12 Elapsed Time: 0:00:18\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}